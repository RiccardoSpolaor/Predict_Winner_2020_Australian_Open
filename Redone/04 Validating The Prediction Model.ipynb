{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# Web Intelligence\n",
    "\n",
    "# Who will win the Tennis Australian Open 2020?\n",
    "\n",
    "## 05 Prediction 1 - Random Forest\n",
    "\n",
    "### Riccardo Spolaor (864877)\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv('./datasets/dataframe03.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>csvID</th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>RankA</th>\n",
       "      <th>...</th>\n",
       "      <th>Isner J.A</th>\n",
       "      <th>Isner J.B</th>\n",
       "      <th>Moya C.A</th>\n",
       "      <th>Moya C.B</th>\n",
       "      <th>Davydenko N.A</th>\n",
       "      <th>Davydenko N.B</th>\n",
       "      <th>Gonzalez F.A</th>\n",
       "      <th>Gonzalez F.B</th>\n",
       "      <th>OtherA</th>\n",
       "      <th>OtherB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>442.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Winner  csvID  ATP  Location  Tournament  Series  Court  Round  Best of  \\\n",
       "0       0      0  1.0         2           0       0      1      0      3.0   \n",
       "1       1      0  1.0         2           0       0      1      0      3.0   \n",
       "2       0      0  1.0         2           0       0      1      0      3.0   \n",
       "3       1      0  1.0         2           0       0      1      0      3.0   \n",
       "4       0      0  1.0         2           0       0      1      0      3.0   \n",
       "5       1      0  1.0         2           0       0      1      0      3.0   \n",
       "6       0      0  1.0         2           0       0      1      0      3.0   \n",
       "7       1      0  1.0         2           0       0      1      0      3.0   \n",
       "8       0      0  1.0         2           0       0      1      0      3.0   \n",
       "9       1      0  1.0         2           0       0      1      0      3.0   \n",
       "\n",
       "   RankA  ...  Isner J.A  Isner J.B  Moya C.A  Moya C.B  Davydenko N.A  \\\n",
       "0   18.0  ...          0          0         0         0              0   \n",
       "1  442.0  ...          0          0         0         0              0   \n",
       "2   23.0  ...          0          0         0         0              0   \n",
       "3   69.0  ...          0          0         0         0              0   \n",
       "4    7.0  ...          0          0         0         0              0   \n",
       "5   99.0  ...          0          0         0         0              0   \n",
       "6   91.0  ...          0          0         0         0              0   \n",
       "7   67.0  ...          0          0         0         0              0   \n",
       "8   79.0  ...          0          0         0         0              0   \n",
       "9   95.0  ...          0          0         0         0              0   \n",
       "\n",
       "   Davydenko N.B  Gonzalez F.A  Gonzalez F.B  OtherA  OtherB  \n",
       "0              0             0             0       1       1  \n",
       "1              0             0             0       1       1  \n",
       "2              0             0             0       0       1  \n",
       "3              0             0             0       1       1  \n",
       "4              0             0             0       0       1  \n",
       "5              0             0             0       1       1  \n",
       "6              0             0             0       1       1  \n",
       "7              0             0             0       1       1  \n",
       "8              0             0             0       1       1  \n",
       "9              0             0             0       1       1  \n",
       "\n",
       "[10 rows x 81 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Winner', 'csvID', 'ATP', 'Location', 'Tournament', 'Series',\n",
       "       'Court', 'Round', 'Best of', 'RankA', 'RankFilledA', 'RankB',\n",
       "       'RankFilledB', 'PtsA', 'PtsFilledA', 'PtsB', 'PtsFilledB', 'MaxA',\n",
       "       'MaxFilledA', 'MaxB', 'MaxFilledB', 'AvgA', 'AvgFilledA', 'AvgB',\n",
       "       'AvgFilledB', 'Carpet', 'Clay', 'Grass', 'Hard', 'Federer R.A',\n",
       "       'Federer R.B', 'Nadal R.A', 'Nadal R.B', 'Djokovic N.A',\n",
       "       'Djokovic N.B', 'Murray A.A', 'Murray A.B', 'Roddick A.A',\n",
       "       'Roddick A.B', 'Ferrer D.A', 'Ferrer D.B', 'Berdych T.A',\n",
       "       'Berdych T.B', 'Hewitt L.A', 'Hewitt L.B', 'Del Potro J.M.A',\n",
       "       'Del Potro J.M.B', 'Tsonga J.W.A', 'Tsonga J.W.B', 'Cilic M.A',\n",
       "       'Cilic M.B', 'Wawrinka S.A', 'Wawrinka S.B', 'Gasquet R.A',\n",
       "       'Gasquet R.B', 'Nishikori K.A', 'Nishikori K.B', 'Monfils G.A',\n",
       "       'Monfils G.B', 'Ferrero J.C.A', 'Ferrero J.C.B', 'Robredo T.A',\n",
       "       'Robredo T.B', 'Nalbandian D.A', 'Nalbandian D.B', 'Raonic M.A',\n",
       "       'Raonic M.B', 'Agassi A.A', 'Agassi A.B', 'Haas T.A', 'Haas T.B',\n",
       "       'Isner J.A', 'Isner J.B', 'Moya C.A', 'Moya C.B', 'Davydenko N.A',\n",
       "       'Davydenko N.B', 'Gonzalez F.A', 'Gonzalez F.B', 'OtherA',\n",
       "       'OtherB'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Vedo similarità tra giocatori che hanno partecipato all' Aus open 2019 rispetto ai giocatori negli anni (HA SENSO USARE JACCARD O C'E' DI MEGLIO?)\\n# Riproporre alla fine, quando dataframe è completo e validare il fatto di droppare righe in base ad accuracy\\n\\nplayers2019 = set(dataframe[dataframe['csvID'] == max(dataframe['csvID'])]['PlayerA'].append(dataframe[dataframe['csvID'] == max(dataframe['csvID'])]['PlayerB']).unique())\\nprint(type(players2019))\\nfor i in range(0,int(max(dataframe['csvID']))) :\\n    players = set(dataframe[dataframe['csvID'] == i]['PlayerA'].append(dataframe[dataframe['csvID'] == i]['PlayerB']).unique())\\n    print ('Jaccard ', i + 2001, ': ', len(players2019 & players) / len( players2019 | players))\\n    \\n# Come c'era da aspettarsi i giocatori sono più simili a quelli del 2019 in rapporto alla cardinalità all'aumentare del tempo\\n# Prendo\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Vedo similarità tra giocatori che hanno partecipato all' Aus open 2019 rispetto ai giocatori negli anni (HA SENSO USARE JACCARD O C'E' DI MEGLIO?)\n",
    "# Riproporre alla fine, quando dataframe è completo e validare il fatto di droppare righe in base ad accuracy\n",
    "\n",
    "players2019 = set(dataframe[dataframe['csvID'] == max(dataframe['csvID'])]['PlayerA'].append(dataframe[dataframe['csvID'] == max(dataframe['csvID'])]['PlayerB']).unique())\n",
    "print(type(players2019))\n",
    "for i in range(0,int(max(dataframe['csvID']))) :\n",
    "    players = set(dataframe[dataframe['csvID'] == i]['PlayerA'].append(dataframe[dataframe['csvID'] == i]['PlayerB']).unique())\n",
    "    print ('Jaccard ', i + 2001, ': ', len(players2019 & players) / len( players2019 | players))\n",
    "    \n",
    "# Come c'era da aspettarsi i giocatori sono più simili a quelli del 2019 in rapporto alla cardinalità all'aumentare del tempo\n",
    "# Prendo\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.drop(['PlayerA', 'PlayerB'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn import tree\\nfrom sklearn.metrics import accuracy_score\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\ndef get_best_dataframe_split (index, df): \\n    print(df.shape)\\n    print(\\'csvID deleted up to: \\', index)\\n\\n    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != \\'Winner\\'],  \\n                                                        dataframe[\\'Winner\\'], test_size=0.33, shuffle = False, stratify=None)\\n    accuracies_valid = []\\n    accuracies_test = []\\n    \\n    for i in range(30,31,2):\\n        rf = RandomForestClassifier(n_estimators=i)\\n        rf.fit(X_train,y_train)\\n\\n        # compute Accuracy\\n        valid_acc = accuracy_score(y_true=y_valid, y_pred=rf.predict(X_valid))\\n        accuracies_valid += [valid_acc]\\n    print (\"\\t Mean Validation Accuracy: {:.3f}\".format(\\n        np.mean(accuracies_valid)) )\\n    \\n\\ncutDataframes = [dataframe.drop(dataframe[dataframe[\\'csvID\\'].isin(range(0, i))].index.values, axis =0) \\n                 for i in range(0, int(max(dataframe[\\'csvID\\'])))]\\n\\nfor i, df in enumerate(cutDataframes):\\n    get_best_dataframe_split (i, df)\\n    \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_best_dataframe_split (index, df): \n",
    "    print(df.shape)\n",
    "    print('csvID deleted up to: ', index)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'],  \n",
    "                                                        dataframe['Winner'], test_size=0.33, shuffle = False, stratify=None)\n",
    "    accuracies_valid = []\n",
    "    accuracies_test = []\n",
    "    \n",
    "    for i in range(30,31,2):\n",
    "        rf = RandomForestClassifier(n_estimators=i)\n",
    "        rf.fit(X_train,y_train)\n",
    "\n",
    "        # compute Accuracy\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=rf.predict(X_valid))\n",
    "        accuracies_valid += [valid_acc]\n",
    "    print (\"\\t Mean Validation Accuracy: {:.3f}\".format(\n",
    "        np.mean(accuracies_valid)) )\n",
    "    \n",
    "\n",
    "cutDataframes = [dataframe.drop(dataframe[dataframe['csvID'].isin(range(0, i))].index.values, axis =0) \n",
    "                 for i in range(0, int(max(dataframe['csvID'])))]\n",
    "\n",
    "for i, df in enumerate(cutDataframes):\n",
    "    get_best_dataframe_split (i, df)\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe = dataframe[dataframe['csvID'] > 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winner</th>\n",
       "      <th>csvID</th>\n",
       "      <th>ATP</th>\n",
       "      <th>Location</th>\n",
       "      <th>Tournament</th>\n",
       "      <th>Series</th>\n",
       "      <th>Court</th>\n",
       "      <th>Round</th>\n",
       "      <th>Best of</th>\n",
       "      <th>RankA</th>\n",
       "      <th>...</th>\n",
       "      <th>Isner J.A</th>\n",
       "      <th>Isner J.B</th>\n",
       "      <th>Moya C.A</th>\n",
       "      <th>Moya C.B</th>\n",
       "      <th>Davydenko N.A</th>\n",
       "      <th>Davydenko N.B</th>\n",
       "      <th>Gonzalez F.A</th>\n",
       "      <th>Gonzalez F.B</th>\n",
       "      <th>OtherA</th>\n",
       "      <th>OtherB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.00000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "      <td>51945.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499990</td>\n",
       "      <td>8.780017</td>\n",
       "      <td>33.145288</td>\n",
       "      <td>55.134662</td>\n",
       "      <td>7.111098</td>\n",
       "      <td>1.328463</td>\n",
       "      <td>0.822447</td>\n",
       "      <td>1.43084</td>\n",
       "      <td>3.374280</td>\n",
       "      <td>76.034958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.006237</td>\n",
       "      <td>0.005275</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.820137</td>\n",
       "      <td>0.821946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500005</td>\n",
       "      <td>5.497453</td>\n",
       "      <td>18.079233</td>\n",
       "      <td>28.209598</td>\n",
       "      <td>9.661308</td>\n",
       "      <td>1.497969</td>\n",
       "      <td>0.382140</td>\n",
       "      <td>2.01872</td>\n",
       "      <td>0.780056</td>\n",
       "      <td>107.370202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078731</td>\n",
       "      <td>0.078731</td>\n",
       "      <td>0.072437</td>\n",
       "      <td>0.067534</td>\n",
       "      <td>0.086980</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>0.072041</td>\n",
       "      <td>0.067251</td>\n",
       "      <td>0.384077</td>\n",
       "      <td>0.382562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2161.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Winner         csvID           ATP      Location    Tournament  \\\n",
       "count  51945.000000  51945.000000  51945.000000  51945.000000  51945.000000   \n",
       "mean       0.499990      8.780017     33.145288     55.134662      7.111098   \n",
       "std        0.500005      5.497453     18.079233     28.209598      9.661308   \n",
       "min        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "25%        0.000000      4.000000     19.000000     34.000000      0.000000   \n",
       "50%        0.000000      9.000000     33.000000     56.000000      0.000000   \n",
       "75%        1.000000     14.000000     49.000000     74.000000     16.000000   \n",
       "max        1.000000     18.000000     69.000000    107.000000     25.000000   \n",
       "\n",
       "             Series         Court        Round       Best of         RankA  \\\n",
       "count  51945.000000  51945.000000  51945.00000  51945.000000  51945.000000   \n",
       "mean       1.328463      0.822447      1.43084      3.374280     76.034958   \n",
       "std        1.497969      0.382140      2.01872      0.780056    107.370202   \n",
       "min        0.000000      0.000000      0.00000      3.000000      1.000000   \n",
       "25%        0.000000      1.000000      0.00000      3.000000     24.000000   \n",
       "50%        1.000000      1.000000      1.00000      3.000000     53.000000   \n",
       "75%        2.000000      1.000000      2.00000      3.000000     92.000000   \n",
       "max        4.000000      1.000000      7.00000      5.000000   2161.000000   \n",
       "\n",
       "       ...     Isner J.A     Isner J.B      Moya C.A      Moya C.B  \\\n",
       "count  ...  51945.000000  51945.000000  51945.000000  51945.000000   \n",
       "mean   ...      0.006237      0.006237      0.005275      0.004582   \n",
       "std    ...      0.078731      0.078731      0.072437      0.067534   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       Davydenko N.A  Davydenko N.B  Gonzalez F.A  Gonzalez F.B        OtherA  \\\n",
       "count   51945.000000   51945.000000  51945.000000  51945.000000  51945.000000   \n",
       "mean        0.007623       0.007585      0.005217      0.004543      0.820137   \n",
       "std         0.086980       0.086762      0.072041      0.067251      0.384077   \n",
       "min         0.000000       0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000       0.000000      0.000000      0.000000      1.000000   \n",
       "50%         0.000000       0.000000      0.000000      0.000000      1.000000   \n",
       "75%         0.000000       0.000000      0.000000      0.000000      1.000000   \n",
       "max         1.000000       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             OtherB  \n",
       "count  51945.000000  \n",
       "mean       0.821946  \n",
       "std        0.382562  \n",
       "min        0.000000  \n",
       "25%        1.000000  \n",
       "50%        1.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 81 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.utils import resample\\nfrom sklearn.tree import DecisionTreeClassifier\\n\\n\\nN_TESTS = 20\\n\\nstats = np.array([])\\n\\nX_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'],  \\n                                                        dataframe['Winner'], test_size=0.33, shuffle = False, stratify=None)\\n\\nn_inst = range(2,100,5)\\nfor n in n_inst:\\n    y_preds = np.array([])\\n    \\n    for i in range(N_TESTS):\\n        Xs, ys = resample(X_train,y_train, n_samples=n)\\n\\n        # train a decision tree classifier\\n        dt = DecisionTreeClassifier(max_leaf_nodes=20)\\n        dt.fit(Xs,ys)\\n        \\n        y_pred = dt.predict(X_valid)\\n        y_preds = np.column_stack( [y_preds, y_pred] ) if y_preds.size else y_pred\\n\\n    dt_bias     = (y_valid-np.mean(y_preds,axis=1))**2\\n    dt_variance = np.var(y_preds,axis=1)\\n    dt_error    = (y_preds - y_valid.values.reshape(-1,1))**2\\n    \\n    run_stats = np.array([dt_error.mean(), dt_bias.mean(), dt_variance.mean()])\\n    \\n    stats = np.column_stack( [stats, run_stats]) if stats.size else run_stats\\n    \\nfig, ax = plt.subplots(figsize=(6,6))\\n\\nax.plot(n_inst,stats[0,:], 'o:', label='Error')\\nax.plot(n_inst,stats[1,:], 'o:', label='Bias$^2$')\\nax.plot(n_inst,stats[2,:], 'o:', label='Variance')\\nax.set_xlabel('Number of instances')\\nax.grid()\\nax.legend()\\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "N_TESTS = 20\n",
    "\n",
    "stats = np.array([])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'],  \n",
    "                                                        dataframe['Winner'], test_size=0.33, shuffle = False, stratify=None)\n",
    "\n",
    "n_inst = range(2,100,5)\n",
    "for n in n_inst:\n",
    "    y_preds = np.array([])\n",
    "    \n",
    "    for i in range(N_TESTS):\n",
    "        Xs, ys = resample(X_train,y_train, n_samples=n)\n",
    "\n",
    "        # train a decision tree classifier\n",
    "        dt = DecisionTreeClassifier(max_leaf_nodes=20)\n",
    "        dt.fit(Xs,ys)\n",
    "        \n",
    "        y_pred = dt.predict(X_valid)\n",
    "        y_preds = np.column_stack( [y_preds, y_pred] ) if y_preds.size else y_pred\n",
    "\n",
    "    dt_bias     = (y_valid-np.mean(y_preds,axis=1))**2\n",
    "    dt_variance = np.var(y_preds,axis=1)\n",
    "    dt_error    = (y_preds - y_valid.values.reshape(-1,1))**2\n",
    "    \n",
    "    run_stats = np.array([dt_error.mean(), dt_bias.mean(), dt_variance.mean()])\n",
    "    \n",
    "    stats = np.column_stack( [stats, run_stats]) if stats.size else run_stats\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.plot(n_inst,stats[0,:], 'o:', label='Error')\n",
    "ax.plot(n_inst,stats[1,:], 'o:', label='Bias$^2$')\n",
    "ax.plot(n_inst,stats[2,:], 'o:', label='Variance')\n",
    "ax.set_xlabel('Number of instances')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.utils import resample\\nfrom sklearn.ensemble import RandomForestClassifier\\n\\nN_TESTS = 2\\n\\nstats = np.array([])\\n\\n\\nX_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'],  \\n                                                        dataframe['Winner'], test_size=0.33, shuffle = False, stratify=None)\\n\\nboosts = range(2,100,10)\\nfor l in boosts:\\n    y_preds = np.array([])\\n    \\n    for i in range(N_TESTS):\\n        Xs, ys = resample(X_train,y_train, n_samples=int(0.67*len(y_train)) )\\n\\n        # train a decision tree classifier\\n        rf = RandomForestClassifier(n_estimators=l, n_jobs = -1)\\n        rf.fit(Xs,ys)\\n        \\n        y_pred = rf.predict(X_valid)\\n        y_preds = np.column_stack( [y_preds, y_pred] ) if y_preds.size else y_pred\\n\\n    dt_bias     = (y_valid-np.mean(y_preds,axis=1))**2\\n    dt_variance = np.var(y_preds,axis=1)\\n    dt_error    = (y_preds - y_valid.values.reshape(-1,1))**2\\n\\n    \\n    run_stats = np.array([dt_error.mean(), dt_bias.mean(), dt_variance.mean()])\\n    \\n    stats = np.column_stack( [stats, run_stats]) if stats.size else run_stats\\n    \\nfig, ax = plt.subplots(figsize=(6,6))\\n\\nax.plot(boosts,stats[0,:], 'o:', label='Error')\\nax.plot(boosts,stats[1,:], 'o:', label='Bias$^2$')\\nax.plot(boosts,stats[2,:], 'o:', label='Variance')\\nax.set_xlabel('Number of Trees')\\nax.grid()\\nax.legend()\\n\\nprint (stats[:,-1])\\n\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "N_TESTS = 2\n",
    "\n",
    "stats = np.array([])\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'],  \n",
    "                                                        dataframe['Winner'], test_size=0.33, shuffle = False, stratify=None)\n",
    "\n",
    "boosts = range(2,100,10)\n",
    "for l in boosts:\n",
    "    y_preds = np.array([])\n",
    "    \n",
    "    for i in range(N_TESTS):\n",
    "        Xs, ys = resample(X_train,y_train, n_samples=int(0.67*len(y_train)) )\n",
    "\n",
    "        # train a decision tree classifier\n",
    "        rf = RandomForestClassifier(n_estimators=l, n_jobs = -1)\n",
    "        rf.fit(Xs,ys)\n",
    "        \n",
    "        y_pred = rf.predict(X_valid)\n",
    "        y_preds = np.column_stack( [y_preds, y_pred] ) if y_preds.size else y_pred\n",
    "\n",
    "    dt_bias     = (y_valid-np.mean(y_preds,axis=1))**2\n",
    "    dt_variance = np.var(y_preds,axis=1)\n",
    "    dt_error    = (y_preds - y_valid.values.reshape(-1,1))**2\n",
    "\n",
    "    \n",
    "    run_stats = np.array([dt_error.mean(), dt_bias.mean(), dt_variance.mean()])\n",
    "    \n",
    "    stats = np.column_stack( [stats, run_stats]) if stats.size else run_stats\n",
    "    \n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "ax.plot(boosts,stats[0,:], 'o:', label='Error')\n",
    "ax.plot(boosts,stats[1,:], 'o:', label='Bias$^2$')\n",
    "ax.plot(boosts,stats[2,:], 'o:', label='Variance')\n",
    "ax.set_xlabel('Number of Trees')\n",
    "ax.grid()\n",
    "ax.legend()\n",
    "\n",
    "print (stats[:,-1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51945, 81)\n",
      "csvID deleted up to:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-0f8b9330613f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcutDataframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mget_best_dataframe_split\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-0f8b9330613f>\u001b[0m in \u001b[0;36mget_best_dataframe_split\u001b[1;34m(index, df)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    814\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    815\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 816\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    817\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    378\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def get_best_dataframe_split (index, df): \n",
    "    print(df.shape)\n",
    "    print('csvID deleted up to: ', index)\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(df.loc[:, df.columns != 'Winner'],  \n",
    "                                                        df['Winner'], test_size=0.33, shuffle = False, stratify=None)\n",
    "    accuracies = []\n",
    "    \n",
    "    for max_depth in range(2,20):\n",
    "\n",
    "        dt = tree.DecisionTreeClassifier(max_depth = max_depth)\n",
    "\n",
    "        dt.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_true=y_train, y_pred=dt.predict(X_train))\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=dt.predict(X_valid))\n",
    "        \n",
    "        accuracies += [[valid_acc, max_depth]]\n",
    "\n",
    "    best_accuracy, best_max_depth = max(accuracies)\n",
    "    print ( \"Best Max Depth\", best_max_depth, \"Best Accuracy\", best_accuracy)\n",
    "    return best_max_depth\n",
    "\n",
    "    \n",
    "\n",
    "cutDataframes = [dataframe.drop(dataframe[dataframe['csvID'].isin(range(0, i))].index.values, axis =0) \n",
    "                 for i in range(0, int(max(dataframe['csvID'])))]\n",
    "\n",
    "for i, df in enumerate(cutDataframes):\n",
    "    get_best_dataframe_split (i, df)\n",
    "    \n",
    "    \n",
    "# Accuratezza diminuisce nel tempo, per questioni di semplicità della grandezza del modello in verticale scelgo il \n",
    "# dataframe da csvID 7 in poi, l'accuratezza diminuisce di poco,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe[dataframe['csvID'] >= 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth:  2 - Train Accuracy: 0.707 - Validation Accuracy: 0.692 \n",
      "Depth:  3 - Train Accuracy: 0.724 - Validation Accuracy: 0.692 \n",
      "Depth:  4 - Train Accuracy: 0.725 - Validation Accuracy: 0.692 \n",
      "Depth:  5 - Train Accuracy: 0.737 - Validation Accuracy: 0.692 \n",
      "Depth:  6 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Depth:  7 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Depth:  8 - Train Accuracy: 0.741 - Validation Accuracy: 0.691 \n",
      "Depth:  9 - Train Accuracy: 0.743 - Validation Accuracy: 0.692 \n",
      "Depth: 10 - Train Accuracy: 0.747 - Validation Accuracy: 0.690 \n",
      "Depth: 11 - Train Accuracy: 0.750 - Validation Accuracy: 0.689 \n",
      "Depth: 12 - Train Accuracy: 0.754 - Validation Accuracy: 0.687 \n",
      "Depth: 13 - Train Accuracy: 0.760 - Validation Accuracy: 0.686 \n",
      "Depth: 14 - Train Accuracy: 0.770 - Validation Accuracy: 0.683 \n",
      "Depth: 15 - Train Accuracy: 0.779 - Validation Accuracy: 0.680 \n",
      "Depth: 16 - Train Accuracy: 0.791 - Validation Accuracy: 0.673 \n",
      "Depth: 17 - Train Accuracy: 0.804 - Validation Accuracy: 0.666 \n",
      "Depth: 18 - Train Accuracy: 0.818 - Validation Accuracy: 0.663 \n",
      "Depth: 19 - Train Accuracy: 0.833 - Validation Accuracy: 0.651 \n",
      "Best Max Depth 6\n",
      "Max Features:  1 - Train Accuracy: 0.536 - Validation Accuracy: 0.590 \n",
      "Max Features:  2 - Train Accuracy: 0.691 - Validation Accuracy: 0.692 \n",
      "Max Features:  3 - Train Accuracy: 0.645 - Validation Accuracy: 0.627 \n",
      "Max Features:  4 - Train Accuracy: 0.689 - Validation Accuracy: 0.672 \n",
      "Max Features:  5 - Train Accuracy: 0.660 - Validation Accuracy: 0.638 \n",
      "Max Features:  6 - Train Accuracy: 0.709 - Validation Accuracy: 0.693 \n",
      "Max Features:  7 - Train Accuracy: 0.718 - Validation Accuracy: 0.692 \n",
      "Max Features:  8 - Train Accuracy: 0.723 - Validation Accuracy: 0.693 \n",
      "Max Features:  9 - Train Accuracy: 0.625 - Validation Accuracy: 0.597 \n",
      "Max Features: 10 - Train Accuracy: 0.722 - Validation Accuracy: 0.693 \n",
      "Max Features: 11 - Train Accuracy: 0.715 - Validation Accuracy: 0.693 \n",
      "Max Features: 12 - Train Accuracy: 0.724 - Validation Accuracy: 0.693 \n",
      "Max Features: 13 - Train Accuracy: 0.713 - Validation Accuracy: 0.688 \n",
      "Max Features: 14 - Train Accuracy: 0.717 - Validation Accuracy: 0.693 \n",
      "Max Features: 15 - Train Accuracy: 0.712 - Validation Accuracy: 0.693 \n",
      "Max Features: 16 - Train Accuracy: 0.730 - Validation Accuracy: 0.693 \n",
      "Max Features: 17 - Train Accuracy: 0.718 - Validation Accuracy: 0.692 \n",
      "Max Features: 18 - Train Accuracy: 0.721 - Validation Accuracy: 0.691 \n",
      "Max Features: 19 - Train Accuracy: 0.731 - Validation Accuracy: 0.692 \n",
      "Max Features: 20 - Train Accuracy: 0.724 - Validation Accuracy: 0.692 \n",
      "Max Features: 21 - Train Accuracy: 0.721 - Validation Accuracy: 0.692 \n",
      "Max Features: 22 - Train Accuracy: 0.724 - Validation Accuracy: 0.693 \n",
      "Max Features: 23 - Train Accuracy: 0.728 - Validation Accuracy: 0.693 \n",
      "Max Features: 24 - Train Accuracy: 0.725 - Validation Accuracy: 0.693 \n",
      "Max Features: 25 - Train Accuracy: 0.722 - Validation Accuracy: 0.693 \n",
      "Max Features: 26 - Train Accuracy: 0.723 - Validation Accuracy: 0.693 \n",
      "Max Features: 27 - Train Accuracy: 0.731 - Validation Accuracy: 0.692 \n",
      "Max Features: 28 - Train Accuracy: 0.734 - Validation Accuracy: 0.693 \n",
      "Max Features: 29 - Train Accuracy: 0.725 - Validation Accuracy: 0.692 \n",
      "Max Features: 30 - Train Accuracy: 0.726 - Validation Accuracy: 0.692 \n",
      "Max Features: 31 - Train Accuracy: 0.726 - Validation Accuracy: 0.692 \n",
      "Max Features: 32 - Train Accuracy: 0.731 - Validation Accuracy: 0.692 \n",
      "Max Features: 33 - Train Accuracy: 0.727 - Validation Accuracy: 0.692 \n",
      "Max Features: 34 - Train Accuracy: 0.727 - Validation Accuracy: 0.693 \n",
      "Max Features: 35 - Train Accuracy: 0.723 - Validation Accuracy: 0.690 \n",
      "Max Features: 36 - Train Accuracy: 0.733 - Validation Accuracy: 0.693 \n",
      "Max Features: 37 - Train Accuracy: 0.733 - Validation Accuracy: 0.693 \n",
      "Max Features: 38 - Train Accuracy: 0.735 - Validation Accuracy: 0.692 \n",
      "Max Features: 39 - Train Accuracy: 0.727 - Validation Accuracy: 0.692 \n",
      "Max Features: 40 - Train Accuracy: 0.738 - Validation Accuracy: 0.693 \n",
      "Max Features: 41 - Train Accuracy: 0.734 - Validation Accuracy: 0.693 \n",
      "Max Features: 42 - Train Accuracy: 0.723 - Validation Accuracy: 0.691 \n",
      "Max Features: 43 - Train Accuracy: 0.732 - Validation Accuracy: 0.693 \n",
      "Max Features: 44 - Train Accuracy: 0.735 - Validation Accuracy: 0.693 \n",
      "Max Features: 45 - Train Accuracy: 0.738 - Validation Accuracy: 0.693 \n",
      "Max Features: 46 - Train Accuracy: 0.730 - Validation Accuracy: 0.692 \n",
      "Max Features: 47 - Train Accuracy: 0.737 - Validation Accuracy: 0.692 \n",
      "Max Features: 48 - Train Accuracy: 0.732 - Validation Accuracy: 0.692 \n",
      "Max Features: 49 - Train Accuracy: 0.738 - Validation Accuracy: 0.692 \n",
      "Max Features: 50 - Train Accuracy: 0.737 - Validation Accuracy: 0.693 \n",
      "Max Features: 51 - Train Accuracy: 0.733 - Validation Accuracy: 0.692 \n",
      "Max Features: 52 - Train Accuracy: 0.734 - Validation Accuracy: 0.693 \n",
      "Max Features: 53 - Train Accuracy: 0.731 - Validation Accuracy: 0.693 \n",
      "Max Features: 54 - Train Accuracy: 0.734 - Validation Accuracy: 0.693 \n",
      "Max Features: 55 - Train Accuracy: 0.737 - Validation Accuracy: 0.692 \n",
      "Max Features: 56 - Train Accuracy: 0.731 - Validation Accuracy: 0.692 \n",
      "Max Features: 57 - Train Accuracy: 0.738 - Validation Accuracy: 0.692 \n",
      "Max Features: 58 - Train Accuracy: 0.729 - Validation Accuracy: 0.693 \n",
      "Max Features: 59 - Train Accuracy: 0.737 - Validation Accuracy: 0.692 \n",
      "Max Features: 60 - Train Accuracy: 0.733 - Validation Accuracy: 0.693 \n",
      "Max Features: 61 - Train Accuracy: 0.737 - Validation Accuracy: 0.693 \n",
      "Max Features: 62 - Train Accuracy: 0.735 - Validation Accuracy: 0.692 \n",
      "Max Features: 63 - Train Accuracy: 0.736 - Validation Accuracy: 0.691 \n",
      "Max Features: 64 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 65 - Train Accuracy: 0.738 - Validation Accuracy: 0.692 \n",
      "Max Features: 66 - Train Accuracy: 0.738 - Validation Accuracy: 0.693 \n",
      "Max Features: 67 - Train Accuracy: 0.738 - Validation Accuracy: 0.692 \n",
      "Max Features: 68 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 69 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 70 - Train Accuracy: 0.738 - Validation Accuracy: 0.693 \n",
      "Max Features: 71 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 72 - Train Accuracy: 0.738 - Validation Accuracy: 0.692 \n",
      "Max Features: 73 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 74 - Train Accuracy: 0.738 - Validation Accuracy: 0.692 \n",
      "Max Features: 75 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 76 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 77 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Max Features: 78 - Train Accuracy: 0.738 - Validation Accuracy: 0.692 \n",
      "Max Features: 79 - Train Accuracy: 0.739 - Validation Accuracy: 0.692 \n",
      "Best Max Features 36\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def tune_tree_depth():\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'], \n",
    "                                                              dataframe['Winner'], \n",
    "                                                              test_size = 0.33, \n",
    "                                                              stratify = None, shuffle = False)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for max_depth in range(2,20):\n",
    "\n",
    "        dt = tree.DecisionTreeClassifier(max_depth = max_depth)\n",
    "\n",
    "        dt.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_true=y_train, y_pred=dt.predict(X_train))\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=dt.predict(X_valid))\n",
    "        print (\"Depth: {:2d} - Train Accuracy: {:.3f} - Validation Accuracy: {:.3f} \".format(\n",
    "            max_depth,  train_acc, valid_acc))\n",
    "\n",
    "        accuracies += [[valid_acc, max_depth]]\n",
    "\n",
    "    best_accuracy, best_max_depth = max(accuracies)\n",
    "    print ( \"Best Max Depth\", best_max_depth)\n",
    "    return best_max_depth\n",
    "\n",
    "\n",
    "def tune_tree_max_features(depth):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'], \n",
    "                                                              dataframe['Winner'], \n",
    "                                                              test_size = 0.33, \n",
    "                                                              stratify = None, shuffle = False)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for max_features in range(1,X_train.shape[1]):\n",
    "\n",
    "        dt = tree.DecisionTreeClassifier(max_depth = depth, max_features = max_features)\n",
    "\n",
    "        dt.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_true=y_train, y_pred=dt.predict(X_train))\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=dt.predict(X_valid))\n",
    "        print (\"Max Features: {:2d} - Train Accuracy: {:.3f} - Validation Accuracy: {:.3f} \".format(\n",
    "            max_features,  train_acc, valid_acc))\n",
    "\n",
    "        accuracies += [[valid_acc, max_features]]\n",
    "\n",
    "    best_accuracy, best_max_features = max(accuracies)\n",
    "    print ( \"Best Max Features\", best_max_features)\n",
    "    return best_max_features\n",
    "\n",
    "def validate_tree_classifier():\n",
    "    hyper_parameters = {}\n",
    "    hyper_parameters['depth'] = tune_tree_depth()\n",
    "    hyper_parameters['max_features'] = tune_tree_max_features(depth = hyper_parameters['depth'])\n",
    "    return hyper_parameters\n",
    "    \n",
    "tree_best_features = validate_tree_classifier()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators: 50 - Train Accuracy: 0.738 - Validation Accuracy: 0.694 \n",
      "Estimators: 100 - Train Accuracy: 0.737 - Validation Accuracy: 0.694 \n",
      "Estimators: 150 - Train Accuracy: 0.738 - Validation Accuracy: 0.694 \n",
      "Estimators: 200 - Train Accuracy: 0.737 - Validation Accuracy: 0.694 \n",
      "Estimators: 250 - Train Accuracy: 0.737 - Validation Accuracy: 0.694 \n",
      "Estimators: 300 - Train Accuracy: 0.738 - Validation Accuracy: 0.694 \n",
      "Estimators: 350 - Train Accuracy: 0.738 - Validation Accuracy: 0.694 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-020ddf50c354>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mbagged_tree_best_n_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_best_bagged_tree_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-020ddf50c354>\u001b[0m in \u001b[0;36mget_best_bagged_tree_estimators\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mbagged_dt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBaggingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mbagged_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbagged_dt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \"\"\"\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    377\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 verbose=self.verbose)\n\u001b[1;32m--> 379\u001b[1;33m             for i in range(n_jobs))\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "\n",
    "\n",
    "def get_best_bagged_tree_estimators():\n",
    "    \n",
    "    dt = tree.DecisionTreeClassifier(max_depth = tree_best_features['depth'], \n",
    "                                     max_features = tree_best_features['max_features'])\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'], \n",
    "                                                              dataframe['Winner'], \n",
    "                                                              test_size = 0.33, \n",
    "                                                              stratify = None, shuffle = False)\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for n_estimators in range(50,301,50):\n",
    "\n",
    "        bagged_dt = BaggingClassifier(dt, n_estimators=n_estimators, n_jobs = -1)\n",
    "\n",
    "        bagged_dt.fit(X_train,y_train)\n",
    "\n",
    "        train_acc = accuracy_score(y_true=y_train, y_pred=bagged_dt.predict(X_train))\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=bagged_dt.predict(X_valid))\n",
    "        print (\"Estimators: {:2d} - Train Accuracy: {:.3f} - Validation Accuracy: {:.3f} \".format(\n",
    "            n_estimators,  train_acc, valid_acc))\n",
    "\n",
    "        accuracies += [[valid_acc, n_estimators]]\n",
    "\n",
    "    best_accuracy, best_n_estimators = max(accuracies)\n",
    "    print ( \"Best Number of Estimators\", best_n_estimators)\n",
    "    return best_n_estimators\n",
    "\n",
    "\n",
    "bagged_tree_best_n_estimators = get_best_bagged_tree_estimators()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Estimators: 50 - Validation Accuracy: 0.681\n",
      "\t Estimators: 100 - Validation Accuracy: 0.684\n",
      "\t Estimators: 150 - Validation Accuracy: 0.686\n",
      "\t Estimators: 200 - Validation Accuracy: 0.683\n",
      "\t Estimators: 250 - Validation Accuracy: 0.686\n",
      "\t Estimators: 300 - Validation Accuracy: 0.686\n",
      "Best Estimators Number 300\n",
      "\t Depth:  2 - Validation Accuracy: 0.694\n",
      "\t Depth:  3 - Validation Accuracy: 0.694\n",
      "\t Depth:  4 - Validation Accuracy: 0.694\n",
      "\t Depth:  5 - Validation Accuracy: 0.694\n",
      "\t Depth:  6 - Validation Accuracy: 0.694\n",
      "\t Depth:  7 - Validation Accuracy: 0.695\n",
      "\t Depth:  8 - Validation Accuracy: 0.694\n",
      "\t Depth:  9 - Validation Accuracy: 0.695\n",
      "\t Depth: 10 - Validation Accuracy: 0.694\n",
      "\t Depth: 11 - Validation Accuracy: 0.694\n",
      "\t Depth: 12 - Validation Accuracy: 0.695\n",
      "\t Depth: 13 - Validation Accuracy: 0.695\n",
      "\t Depth: 14 - Validation Accuracy: 0.694\n",
      "\t Depth: 15 - Validation Accuracy: 0.694\n",
      "\t Depth: 16 - Validation Accuracy: 0.694\n",
      "\t Depth: 17 - Validation Accuracy: 0.694\n",
      "\t Depth: 18 - Validation Accuracy: 0.693\n",
      "\t Depth: 19 - Validation Accuracy: 0.692\n",
      "Best Depth 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def tune_forest_estimators():\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'], \n",
    "                                                              dataframe['Winner'], \n",
    "                                                              test_size = 0.33, \n",
    "                                                              stratify = None, shuffle = False)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for estimators in range(50,301,50):\n",
    "        rf = RandomForestClassifier(n_estimators=estimators, n_jobs = -1) # Traininig su più core n_jobs -1\n",
    "        rf.fit(X_train,y_train)\n",
    "\n",
    "        # compute Accuracy\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=rf.predict(X_valid))\n",
    "        accuracies += [[valid_acc, estimators]]\n",
    "        print (\"\\t Estimators: {:2d} - Validation Accuracy: {:.3f}\".format(\n",
    "            estimators, valid_acc))\n",
    "\n",
    "    best_accuracy, best_estimators = max(accuracies)\n",
    "    print ( \"Best Estimators Number\", best_estimators)\n",
    "    return best_estimators\n",
    "\n",
    "\n",
    "def tune_forest_depth(n_estimators):\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'], \n",
    "                                                              dataframe['Winner'], \n",
    "                                                              test_size = 0.33, \n",
    "                                                              stratify = None, shuffle = False)\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for max_depth in range(2,20):\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, max_depth = max_depth, n_jobs = -1) # Traininig su più core n_jobs -1\n",
    "        rf.fit(X_train,y_train)\n",
    "\n",
    "        # compute Accuracy\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=rf.predict(X_valid))\n",
    "        accuracies += [[valid_acc, max_depth]]\n",
    "        print (\"\\t Depth: {:2d} - Validation Accuracy: {:.3f}\".format(\n",
    "            max_depth, valid_acc))\n",
    "\n",
    "    best_accuracy, best_depth = max(accuracies)\n",
    "    print ( \"Best Depth\", best_depth)\n",
    "    return best_depth\n",
    "\n",
    "\n",
    "\n",
    "def validate_forest_classifier():\n",
    "    hyper_parameters = {}\n",
    "    hyper_parameters['n_estimators'] = tune_forest_estimators()\n",
    "    hyper_parameters['max_depth'] = tune_forest_depth(n_estimators = hyper_parameters['n_estimators'])\n",
    "    return hyper_parameters\n",
    "    \n",
    "forest_best_features = validate_forest_classifier()\n",
    "    \n",
    "    \n",
    "# Max Features lasciato perdere perché inutile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Estimators: 50 - Validation Accuracy: 0.687\n",
      "\t Estimators: 100 - Validation Accuracy: 0.686\n",
      "\t Estimators: 150 - Validation Accuracy: 0.685\n",
      "\t Estimators: 200 - Validation Accuracy: 0.686\n",
      "\t Estimators: 250 - Validation Accuracy: 0.686\n",
      "\t Estimators: 300 - Validation Accuracy: 0.686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lb\n",
    "\n",
    "#Accuracy validation with a random forest classifier\n",
    "\n",
    "def getRandomForestPrediction (): \n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'],  \n",
    "                                                        dataframe['Winner'], test_size=0.33, shuffle = False, stratify=None)\n",
    "    \n",
    "    accuracies_valid = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(50,301,50):\n",
    "        rf = RandomForestClassifier(n_estimators=i, n_jobs = -1, max_depth = 5) # Traininig su più core n_jobs -1\n",
    "        rf.fit(X_train,y_train)\n",
    "\n",
    "        # compute Accuracy\n",
    "        valid_acc = accuracy_score(y_true=y_valid, y_pred=rf.predict(X_valid))\n",
    "        accuracies_valid += [valid_acc]\n",
    "        print (\"\\t Estimators: {:2d} - Validation Accuracy: {:.3f}\".format(\n",
    "            i, valid_acc))\n",
    "\n",
    "getRandomForestPrediction()\n",
    "\n",
    "# min sample split minimo numero di istanze per continuare a splittare\n",
    "# min impurity decrease\n",
    "# gridsearch per tunare gli iperparametri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-57f32a93e598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# COMMENTO DA AGGIUNGERE SEMPRE PER USAR GRAPHVIZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import graphviz \n",
    "import os\n",
    "\n",
    "dt = tree.DecisionTreeClassifier(max_depth= 5)\n",
    "dt.fit(X_train,y_train)\n",
    "\n",
    "# COMMENTO DA AGGIUNGERE SEMPRE PER USAR GRAPHVIZ\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Users/ricca/Anaconda3/Graphviz/release/bin/'\n",
    "\n",
    "\n",
    "f_names = [\"Feature 1\", \"Feature 2\"]\n",
    "\n",
    "c_names = [\"Class 0\",\"Class 1\"]\n",
    "\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                                feature_names=dataframe.loc[:, dataframe.columns != 'Winner'].columns, class_names=['0','1'],  \n",
    "                                filled=True, rounded=True, special_characters=True)  \n",
    "\n",
    "\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.tree_.node_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "\n",
    "def getPredImportance (): \n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(dataframe.loc[:, dataframe.columns != 'Winner'],  \n",
    "                                                        dataframe['Winner'], test_size=0.33, shuffle = False, stratify=None)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=250)\n",
    "    rf.fit(X_train,y_train)\n",
    "\n",
    "    return rf.feature_importances_\n",
    "\n",
    "featImp = getPredImportance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print feature importance\n",
    "\n",
    "for (j,k) in sorted((e,i) for i,e in enumerate(featImp)):\n",
    "    print(dataframe.columns[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.feature_selection import RFE\n",
    "\n",
    "rf_small = RandomForestClassifier(n_estimators=20)\n",
    "selector = RFE(rf_small, \n",
    "                 step=1, # features removed at each step\n",
    "                 n_features_to_select=1 # selected features\n",
    "                )\n",
    "fit = selector.fit(dataframe.loc[:, dataframe.columns != 'Winner'],  \n",
    "                                                        dataframe['Winner'])\n",
    "                                                        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy_score(y_true=dataframe['Winner'], y_pred=rf.predict(fit.predict(dataframe.loc[:, dataframe.columns != 'Winner'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
